{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d305748-1152-4f25-be24-145b56d24671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-25 13:27:23.515256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737811643.537139 3020348 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737811643.543929 3020348 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-25 13:27:23.569254: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "import random\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import transformers\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig,BertTokenizer,get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a7af8d7-f309-42bf-8db5-f4fceec7bc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45aca604-00d2-49c8-ab9c-abc077d3a3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>category</th>\n",
       "      <th>sourcePort</th>\n",
       "      <th>destinationPort</th>\n",
       "      <th>packetSize</th>\n",
       "      <th>word_vector</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>55082</td>\n",
       "      <td>80</td>\n",
       "      <td>282.0</td>\n",
       "      <td>['0.0000040561', '0.0110203006', '0.0000202803...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>49096</td>\n",
       "      <td>80</td>\n",
       "      <td>1336.0</td>\n",
       "      <td>['0.0003691010', '0.0367275751', '0.0760753615...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>32925</td>\n",
       "      <td>443</td>\n",
       "      <td>548.0</td>\n",
       "      <td>['0.0014398994', '0.0390070778', '0.2984120546...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>57278</td>\n",
       "      <td>1458.0</td>\n",
       "      <td>['0.0597254051', '0.0072238334', '0.4154860168...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>56700</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>['0.0542862358', '0.0358798597', '0.6726926119...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143573</th>\n",
       "      <td>143573</td>\n",
       "      <td>18</td>\n",
       "      <td>80</td>\n",
       "      <td>63160</td>\n",
       "      <td>1538.0</td>\n",
       "      <td>['0.3877912754', '0.3877953315', '0.3877993875...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143574</th>\n",
       "      <td>143574</td>\n",
       "      <td>7</td>\n",
       "      <td>57272</td>\n",
       "      <td>53</td>\n",
       "      <td>300.0</td>\n",
       "      <td>['0.0574661826', '0.0574702387', '0.0232168570...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143575</th>\n",
       "      <td>143575</td>\n",
       "      <td>18</td>\n",
       "      <td>36568</td>\n",
       "      <td>443</td>\n",
       "      <td>701.0</td>\n",
       "      <td>['0.0003691010', '0.0000202803', '0.0000973453...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143576</th>\n",
       "      <td>143576</td>\n",
       "      <td>16</td>\n",
       "      <td>1556</td>\n",
       "      <td>47421</td>\n",
       "      <td>29694.0</td>\n",
       "      <td>['0.2313451905', '0.0127522359', '0.2204911882...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143577</th>\n",
       "      <td>143577</td>\n",
       "      <td>11</td>\n",
       "      <td>33112</td>\n",
       "      <td>80</td>\n",
       "      <td>811.0</td>\n",
       "      <td>['0.0003691010', '0.0761362023', '0.0760753615...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143578 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  category  sourcePort  destinationPort  packetSize  \\\n",
       "0                0        23       55082               80       282.0   \n",
       "1                1        11       49096               80      1336.0   \n",
       "2                2        18       32925              443       548.0   \n",
       "3                3        18          80            57278      1458.0   \n",
       "4                4        18          80            56700      1538.0   \n",
       "...            ...       ...         ...              ...         ...   \n",
       "143573      143573        18          80            63160      1538.0   \n",
       "143574      143574         7       57272               53       300.0   \n",
       "143575      143575        18       36568              443       701.0   \n",
       "143576      143576        16        1556            47421     29694.0   \n",
       "143577      143577        11       33112               80       811.0   \n",
       "\n",
       "                                              word_vector  label  \n",
       "0       ['0.0000040561', '0.0110203006', '0.0000202803...      1  \n",
       "1       ['0.0003691010', '0.0367275751', '0.0760753615...      2  \n",
       "2       ['0.0014398994', '0.0390070778', '0.2984120546...      1  \n",
       "3       ['0.0597254051', '0.0072238334', '0.4154860168...      2  \n",
       "4       ['0.0542862358', '0.0358798597', '0.6726926119...      2  \n",
       "...                                                   ...    ...  \n",
       "143573  ['0.3877912754', '0.3877953315', '0.3877993875...      2  \n",
       "143574  ['0.0574661826', '0.0574702387', '0.0232168570...      2  \n",
       "143575  ['0.0003691010', '0.0000202803', '0.0000973453...      1  \n",
       "143576  ['0.2313451905', '0.0127522359', '0.2204911882...      2  \n",
       "143577  ['0.0003691010', '0.0761362023', '0.0760753615...      1  \n",
       "\n",
       "[143578 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.tsv',sep='\\t')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "981534af-b214-4d38-8f7d-70a91fbb41a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  category  sourcePort  destinationPort  packetSize  \\\n",
      "0           0        23       55082               80       282.0   \n",
      "1           1        11       49096               80      1336.0   \n",
      "2           2        18       32925              443       548.0   \n",
      "3           3        18          80            57278      1458.0   \n",
      "4           4        18          80            56700      1538.0   \n",
      "\n",
      "                                         word_vector  label  \n",
      "0  ['0.0000040561', '0.0110203006', '0.0000202803...      0  \n",
      "1  ['0.0003691010', '0.0367275751', '0.0760753615...      1  \n",
      "2  ['0.0014398994', '0.0390070778', '0.2984120546...      0  \n",
      "3  ['0.0597254051', '0.0072238334', '0.4154860168...      1  \n",
      "4  ['0.0542862358', '0.0358798597', '0.6726926119...      1  \n"
     ]
    }
   ],
   "source": [
    "# Load your dataset (assuming you have a list of packets and labels)\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i,6]=  df.iloc[i,6]-1\n",
    "print(df.head())\n",
    "packets = df['word_vector']\n",
    "labels = df['label'].tolist()\n",
    "dfFeature = list()\n",
    "for index in range(len(packets)):\n",
    "  Str = re.sub(\"[^A-Za-z0-9.]+\", \" \",packets[index]).strip()\n",
    "  dfFeature.append(Str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f67d575-3b55-4d6e-a931-79c441005ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143578\n"
     ]
    }
   ],
   "source": [
    "print(len(dfFeature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a777f9b-f9bb-4201-8e57-a8bde372b45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87e5bb66-b770-45c9-818d-ae4d6ac384fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  0.0000040561 0.0110203006 0.0000202803 0.0000973453 0.8533533432 0.0000243363 0.0739094283 0.0000730090 0.0000770650 0.8668600053 0.0001338498 0.8668640613 0.8668681174 0.8668721734 0.0012857693 0.0012938814 0.0012898254\n",
      "Tokenized:  ['0', '.', '000', '##00', '##40', '##56', '##1', '0', '.', '01', '##10', '##20', '##30', '##0', '##6', '0', '.', '000', '##0', '##20', '##28', '##0', '##3', '0', '.', '000', '##0', '##9', '##7', '##34', '##53', '0', '.', '85', '##33', '##53', '##34', '##32', '0', '.', '000', '##0', '##24', '##33', '##6', '##3', '0', '.', '07', '##39', '##0', '##9', '##42', '##8', '##3', '0', '.', '000', '##0', '##7', '##30', '##0', '##90', '0', '.', '000', '##0', '##7', '##70', '##65', '##0', '0', '.', '86', '##6', '##86', '##00', '##0', '##53', '0', '.', '000', '##13', '##38', '##49', '##8', '0', '.', '86', '##6', '##86', '##40', '##6', '##13', '0', '.', '86', '##6', '##86', '##8', '##11', '##7', '##4', '0', '.', '86', '##6', '##8', '##7', '##21', '##7', '##34', '0', '.', '001', '##28', '##57', '##6', '##9', '##3', '0', '.', '001', '##29', '##38', '##8', '##14', '0', '.', '001', '##28', '##9', '##8', '##25', '##4']\n",
      "Token IDs:  [1014, 1012, 2199, 8889, 12740, 26976, 2487, 1014, 1012, 5890, 10790, 11387, 14142, 2692, 2575, 1014, 1012, 2199, 2692, 11387, 22407, 2692, 2509, 1014, 1012, 2199, 2692, 2683, 2581, 22022, 22275, 1014, 1012, 5594, 22394, 22275, 22022, 16703, 1014, 1012, 2199, 2692, 18827, 22394, 2575, 2509, 1014, 1012, 5718, 23499, 2692, 2683, 20958, 2620, 2509, 1014, 1012, 2199, 2692, 2581, 14142, 2692, 21057, 1014, 1012, 2199, 2692, 2581, 19841, 26187, 2692, 1014, 1012, 6564, 2575, 20842, 8889, 2692, 22275, 1014, 1012, 2199, 17134, 22025, 26224, 2620, 1014, 1012, 6564, 2575, 20842, 12740, 2575, 17134, 1014, 1012, 6564, 2575, 20842, 2620, 14526, 2581, 2549, 1014, 1012, 6564, 2575, 2620, 2581, 17465, 2581, 22022, 1014, 1012, 25604, 22407, 28311, 2575, 2683, 2509, 1014, 1012, 25604, 24594, 22025, 2620, 16932, 1014, 1012, 25604, 22407, 2683, 2620, 17788, 2549]\n"
     ]
    }
   ],
   "source": [
    "print(' Original: ', dfFeature[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(dfFeature[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(dfFeature[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99953347-41a9-4f20-a437-6c745b77ce4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/sankarkumar/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original:  0.0000040561 0.0110203006 0.0000202803 0.0000973453 0.8533533432 0.0000243363 0.0739094283 0.0000730090 0.0000770650 0.8668600053 0.0001338498 0.8668640613 0.8668681174 0.8668721734 0.0012857693 0.0012938814 0.0012898254\n",
      "\n",
      "Token IDs: tensor([  101,  1014,  1012,  2199,  8889, 12740, 26976,  2487,  1014,  1012,\n",
      "         5890, 10790, 11387, 14142,  2692,  2575,  1014,  1012,  2199,  2692,\n",
      "        11387, 22407,  2692,  2509,  1014,  1012,  2199,  2692,  2683,  2581,\n",
      "        22022, 22275,  1014,  1012,  5594, 22394, 22275, 22022, 16703,  1014,\n",
      "         1012,  2199,  2692, 18827, 22394,  2575,  2509,  1014,  1012,  5718,\n",
      "        23499,  2692,  2683, 20958,  2620,  2509,  1014,  1012,  2199,  2692,\n",
      "         2581, 14142,  2692, 21057,  1014,  1012,  2199,  2692,  2581, 19841,\n",
      "        26187,  2692,  1014,  1012,  6564,  2575, 20842,  8889,  2692, 22275,\n",
      "         1014,  1012,  2199, 17134, 22025, 26224,  2620,  1014,  1012,  6564,\n",
      "         2575, 20842, 12740,  2575, 17134,  1014,  1012,  6564,  2575, 20842,\n",
      "         2620, 14526,  2581,  2549,  1014,  1012,  6564,  2575,  2620,  2581,\n",
      "        17465,  2581, 22022,  1014,  1012, 25604, 22407, 28311,  2575,  2683,\n",
      "         2509,  1014,  1012, 25604, 24594, 22025,  2620, 16932,  1014,  1012,\n",
      "        25604, 22407,  2683,  2620, 17788,  2549,   102,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0])\n",
      "\n",
      "Attension Mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every tweet...\n",
    "for tweet in dfFeature:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start- for classification tasks\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens \n",
    "    #   (7) The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them.\n",
    "    ##      For the BertTokenizer, 1 indicates a value that should be attended to, while 0 indicates a padded value.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        tweet,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('\\nOriginal: ', dfFeature[0])\n",
    "print('\\nToken IDs:', input_ids[0])\n",
    "print('\\nAttension Mask:', attention_masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37a8a5c4-6e30-4e3e-942f-02e24e3b1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114,862 training samples\n",
      "28,716 validation samples\n"
     ]
    }
   ],
   "source": [
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 80-20 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(dataset))\n",
    "#val_size = int(0.2 * len(dataset))\n",
    "val_size = len(dataset)  - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14b312fb-0a2d-4b55-bef4-fefa900638b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad670bc-8b4e-41c7-95a0-1493bd462fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "GPU Enabled.\n"
     ]
    }
   ],
   "source": [
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "    model = model.cuda()\n",
    "    print(\"\\n\\nGPU Enabled.\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2a970b8-3b3e-4e45-9b64-a0b0d9c028b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sankarkumar/.local/lib/python3.12/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ba92e66-7630-4277-be63-a3ea7d8c1e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 10\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create a schedule with a learning rate that decreases linearly from the initial lr \n",
    "# set in the optimizer to 0, after a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffb29c11-1c45-42d0-8cdc-250bf0f1f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    #print(pred_flat)\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat), pred_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8015226-9384-4419-bf07-e31407ad1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32c4dfea-cb09-412e-a98f-973d7f0b0bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.1396\n",
      "  Training epcoh took: 2:29:36\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9748\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0804\n",
      "  Training epcoh took: 2:46:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9820\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0632\n",
      "  Training epcoh took: 2:29:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9828\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0532\n",
      "  Training epcoh took: 2:28:45\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9846\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0447\n",
      "  Training epcoh took: 2:28:37\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9857\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0383\n",
      "  Training epcoh took: 2:30:06\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9873\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0333\n",
      "  Training epcoh took: 2:30:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9874\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0283\n",
      "  Training epcoh took: 2:29:27\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9881\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0238\n",
      "  Training epcoh took: 2:29:07\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9882\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.0210\n",
      "  Training epcoh took: 2:27:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.9883\n",
      "\n",
      "\n",
      "\n",
      "Total training took 1 day, 3:13:37 (h:mm:ss)\n",
      "\n",
      "\n",
      "Training completed and following are the stats [{'epoch': 1, 'Training Loss': 0.13964608739023368, 'Valid. Loss': 0.08733240833782759, 'Valid. Accur.': 0.9748259052924791, 'Training Time': '2:29:36', 'Validation Time': '0:12:27'}, {'epoch': 2, 'Training Loss': 0.08035029776934834, 'Valid. Loss': 0.06898380317893055, 'Valid. Accur.': 0.9819986072423398, 'Training Time': '2:46:57', 'Validation Time': '0:11:53'}, {'epoch': 3, 'Training Loss': 0.06319656991397392, 'Valid. Loss': 0.06475072148884128, 'Valid. Accur.': 0.9827646239554317, 'Training Time': '2:29:02', 'Validation Time': '0:11:55'}, {'epoch': 4, 'Training Loss': 0.0531644483705002, 'Valid. Loss': 0.05597230138036313, 'Valid. Accur.': 0.984575208913649, 'Training Time': '2:28:45', 'Validation Time': '0:12:37'}, {'epoch': 5, 'Training Loss': 0.04471556295013401, 'Valid. Loss': 0.07261456714926919, 'Valid. Accur.': 0.9856894150417828, 'Training Time': '2:28:37', 'Validation Time': '0:12:20'}, {'epoch': 6, 'Training Loss': 0.03831211049195739, 'Valid. Loss': 0.06646540321129182, 'Valid. Accur.': 0.987291086350975, 'Training Time': '2:30:06', 'Validation Time': '0:12:42'}, {'epoch': 7, 'Training Loss': 0.03331300470621442, 'Valid. Loss': 0.061675261309086696, 'Valid. Accur.': 0.9873607242339832, 'Training Time': '2:30:44', 'Validation Time': '0:12:48'}, {'epoch': 8, 'Training Loss': 0.028283414697617807, 'Valid. Loss': 0.06525705237614896, 'Valid. Accur.': 0.9880571030640668, 'Training Time': '2:29:27', 'Validation Time': '0:12:27'}, {'epoch': 9, 'Training Loss': 0.02379827241146081, 'Valid. Loss': 0.07027065880510157, 'Valid. Accur.': 0.9881963788300836, 'Training Time': '2:29:07', 'Validation Time': '0:11:56'}, {'epoch': 10, 'Training Loss': 0.020957481832772854, 'Valid. Loss': 0.07340877021534578, 'Valid. Accur.': 0.9883356545961003, 'Training Time': '2:27:40', 'Validation Time': '0:11:50'}]!\n"
     ]
    }
   ],
   "source": [
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.4f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = np.Inf\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.4f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy < best_eval_accuracy:\n",
    "        torch.save(model, 'bert_model')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\\n\\n\")\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
    "print(f\"\\n\\nTraining completed and following are the stats {training_stats}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bbcf74f-30a3-4dde-8ba1-2a785f2d441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade torch torchvision torchaudio\n",
    "#export TORCH_USE_CUDA_DSA=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95d7ac23-1248-4a5f-b0d6-3ec729f2a3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer state have been saved to bert_model.pth and optimizer.pth\n"
     ]
    }
   ],
   "source": [
    "#***************Save the model*******************\n",
    "\n",
    "# Define paths to save the model and optimizer state\n",
    "model_save_path = \"bert_model.pth\"\n",
    "optimizer_save_path = \"optimizer.pth\"\n",
    "scheduler_save_path = \"scheduler.pth\"\n",
    "\n",
    "# Save the model's state_dict (parameters)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# Save the optimizer's state_dict\n",
    "torch.save(optimizer.state_dict(), optimizer_save_path)\n",
    "\n",
    "# Save the scheduler's state_dict\n",
    "torch.save(scheduler.state_dict(), scheduler_save_path)\n",
    "\n",
    "print(f\"Model and optimizer state have been saved to {model_save_path} and {optimizer_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "527dd5f5-8c02-4f5f-bf9c-0671b3e8b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_3020348/467201651.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n",
      "/tmp/ipykernel_3020348/467201651.py:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  optimizer.load_state_dict(torch.load(optimizer_save_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model, optimizer, and scheduler states have been loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3020348/467201651.py:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  scheduler.load_state_dict(torch.load(scheduler_save_path))\n"
     ]
    }
   ],
   "source": [
    "# *************Loading the Model for Future Training **************************\n",
    "\n",
    "# Define paths to save the model and optimizer state\n",
    "model_save_path = \"bert_model.pth\"\n",
    "optimizer_save_path = \"optimizer.pth\"\n",
    "scheduler_save_path = \"scheduler.pth\"\n",
    "\n",
    "# Initialize the model (same architecture as the saved model)\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",  # Base model\n",
    "    num_labels=2          # Adjust to match your use case\n",
    ")\n",
    "\n",
    "# Load the saved state dictionary into the model\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Recreate and load the optimizer state\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
    "optimizer.load_state_dict(torch.load(optimizer_save_path))\n",
    "\n",
    "# Recreate and load the scheduler state (if applicable)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
    "scheduler.load_state_dict(torch.load(scheduler_save_path))\n",
    "\n",
    "print(\"Model, optimizer, and scheduler states have been loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92800657-82ca-4da7-8915-8d9a0515c4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Testing...\n",
      "\n",
      "  Testing Loss: 0.0276\n",
      "  Testing Accuracy: 0.9945\n",
      "  Testing took: 0:11:59\n"
     ]
    }
   ],
   "source": [
    "# ********* testing************\n",
    "\n",
    "# Put the model in evaluation mode\n",
    "print(\"\\nRunning Testing...\")\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables\n",
    "test_accuracy = 0\n",
    "test_loss = 0\n",
    "nb_test_steps = 0\n",
    "test_dataloader = validation_dataloader\n",
    "p = list()\n",
    "actual_l = list()\n",
    "\n",
    "# Iterate through the test dataset\n",
    "for batch in test_dataloader:\n",
    "    # Unpack the batch\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    # Disable gradient computation\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        output = model(\n",
    "            b_input_ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "        )\n",
    "    \n",
    "    # Get loss and logits\n",
    "    loss = output.loss\n",
    "    logits = output.logits\n",
    "    test_loss += loss.item()\n",
    "\n",
    "    # Move logits and labels to the CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate accuracy for this batch\n",
    "    ft_a, pe = flat_accuracy(logits, label_ids)\n",
    "    test_accuracy += ft_a\n",
    "    p.extend(pe)\n",
    "    actual_l.extend(label_ids)\n",
    "\n",
    "# Calculate the average loss and accuracy\n",
    "avg_test_loss = test_loss / len(test_dataloader)\n",
    "avg_test_accuracy = test_accuracy / len(test_dataloader)\n",
    "\n",
    "# Measure how long the testing process took\n",
    "testing_time = format_time(time.time() - t0)\n",
    "\n",
    "# Print testing results\n",
    "print(\"\")\n",
    "print(\"  Testing Loss: {0:.4f}\".format(avg_test_loss))\n",
    "print(\"  Testing Accuracy: {0:.4f}\".format(avg_test_accuracy))\n",
    "print(\"  Testing took: {:}\".format(testing_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da280aaa-1807-46e8-b798-75d662a99459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9944630171333054\n",
      "Precision:  0.992821299135768\n",
      "Recall:  0.996084189916789\n",
      "F1 score:  0.994450068065203\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "y_test = p\n",
    "y_pred = actual_l\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "print('Precision: ',metrics.precision_score(y_test, y_pred))\n",
    "print('Recall: ',metrics.recall_score(y_test, y_pred))\n",
    "print('F1 score: ',metrics.f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [1,2])\n",
    "cm_display.plot()\n",
    "plt.savefig(\"ConfusionM.png\", dpi=300, format='png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf816831-6ea3-4884-9347-ff4537df08c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
